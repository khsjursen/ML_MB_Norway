{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30c147dc-2053-4ec7-808b-5e41c75f8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotting_functions import plot_prediction\n",
    "from plotting_functions import plot_prediction_per_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b69c3-7107-47db-9678-ab59f76976f3",
   "metadata": {},
   "source": [
    "## Function select_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23bd6ea4-c2a5-493a-91fe-27d392a9ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_variables(df_data, vars, *args, drop=False):\n",
    "    \"\"\"\n",
    "    Select or drop variables (features or labels corresponding to dataframe column names) from Pandas DataFrame based \n",
    "    on one or more lists of variable names and return DataFrame of selected variables.\n",
    "    \n",
    "    Parameters:\n",
    "    df_data : Pd.DataFrame\n",
    "        Training or testing dataset.\n",
    "    vars : list\n",
    "        List of variables (features or labels corresponding to dataframe column names) to select or drop.\n",
    "    *args : tuple\n",
    "        Additional lists of variables.\n",
    "    drop : bool\n",
    "        If False (default), select given variables. If True, drop given variables.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make list of all variables\n",
    "    cols = [y for x in [vars, *args] for y in x]\n",
    "\n",
    "    # If True, drop variables from dataframe. \n",
    "    if drop == True:\n",
    "        df_data_sel = df_data.drop(cols, axis=1)\n",
    "    \n",
    "    #If False, select variables from dataframe.\n",
    "    else: \n",
    "        df_data_sel = df_data[cols]\n",
    "    \n",
    "    return df_data_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0814745-9cb3-44b8-851d-e1dce0eb1d55",
   "metadata": {},
   "source": [
    "### Test for function select_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95698650-c832-4d1d-8967-43076c447633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BREID', 'altitude', 'aspect', 'slope', 'slope_factor',\n",
      "       'altitude_climate', 't2m_oct', 't2m_nov', 't2m_des', 't2m_jan',\n",
      "       't2m_feb', 't2m_mar', 't2m_apr', 't2m_may', 't2m_jun', 't2m_jul',\n",
      "       't2m_aug', 't2m_sep', 'tp_oct', 'tp_nov', 'tp_des', 'tp_jan', 'tp_feb',\n",
      "       'tp_mar', 'tp_apr', 'tp_may', 'tp_jun', 'tp_jul', 'tp_aug', 'tp_sep'],\n",
      "      dtype='object')\n",
      "(833, 30)\n",
      "Index(['BREID', 'balance_netto'], dtype='object')\n",
      "(833, 2)\n",
      "Index(['RGIID', 'GLIMSID', 'utm_zone', 'utm_east_approx', 'utm_north_approx',\n",
      "       'altitude_approx', 'location_description', 'location_id', 'stake_no',\n",
      "       'utm_east',\n",
      "       ...\n",
      "       'tsn_des', 'tsn_jan', 'tsn_feb', 'tsn_mar', 'tsn_apr', 'tsn_may',\n",
      "       'tsn_jun', 'tsn_jul', 'tsn_aug', 'tsn_sep'],\n",
      "      dtype='object', length=271)\n",
      "(833, 271)\n"
     ]
    }
   ],
   "source": [
    "filepath = 'Data/'\n",
    "\n",
    "df_data_train = pd.read_csv(filepath + 'train_test/data_train_all_job_rdsplit.csv', index_col=0)\n",
    "\n",
    "base_cols = ['BREID','altitude','aspect','slope','slope_factor','altitude_climate']\n",
    "temp_cols = ['t2m_oct','t2m_nov','t2m_des','t2m_jan','t2m_feb','t2m_mar','t2m_apr','t2m_may','t2m_jun','t2m_jul','t2m_aug','t2m_sep']\n",
    "prec_cols = ['tp_oct','tp_nov','tp_des','tp_jan','tp_feb','tp_mar','tp_apr','tp_may','tp_jun','tp_jul','tp_aug','tp_sep']\n",
    "label_cols = ['BREID','balance_netto']\n",
    "\n",
    "df_data_train_X = select_variables(df_data_train, base_cols, temp_cols, prec_cols)\n",
    "print(df_data_train_X.columns)\n",
    "print(df_data_train_X.shape)\n",
    "\n",
    "df_data_train_Y = select_variables(df_data_train, label_cols)\n",
    "print(df_data_train_Y.columns)\n",
    "print (df_data_train_Y.shape)\n",
    "\n",
    "df_data_train_X_climate_all = select_variables(df_data_train, base_cols, temp_cols, prec_cols, drop=True)\n",
    "print(df_data_train_X_climate_all.columns)\n",
    "print(df_data_train_X_climate_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d61536-d088-446a-9a54-8f289cf1581d",
   "metadata": {},
   "source": [
    "## Function train_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bcaf46b2-33c9-4f2c-ba01-5c6b5f756d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_model(X, y, split_strategy, params, **kwargs):\n",
    "     \n",
    "    if split_strategy == 'kfold':\n",
    "        \n",
    "        cv_iter = KFold(n_splits = kwargs['n_folds'],\n",
    "                   shuffle = kwargs['shuffle'],\n",
    "                   random_state = kwargs['rand_seed'])\n",
    "        #cv_iter = kf\n",
    "        \n",
    "    elif split_strategy == 'logo':\n",
    "        \n",
    "        logo = LeaveOneGroupOut()\n",
    "        cv_iter = logo.split(X, y, groups=kwargs['groups'])\n",
    "    \n",
    "    else: \n",
    "        raise ValueError(\"Choose cv splitting strategy kfold or logo.\")\n",
    "\n",
    "    # Define model object.\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "    # Set up grid search. \n",
    "    clf = GridSearchCV(xgb_model, \n",
    "                   params, \n",
    "                   cv=cv_iter, # Int or iterator (default for int is kfold)\n",
    "                   verbose=1, # Controls number of messages\n",
    "                   n_jobs=4, # No of parallell jobs\n",
    "                   scoring='neg_mean_squared_error', # Can use multiple metrics\n",
    "                   refit=True, # Default True. For multiple metric evaluation, refit must be str denoting scorer to be used to find the best parameters for refitting the estimator.\n",
    "                   return_train_score=False) # Default False. If False, cv_results_ will not include training scores.\n",
    "\n",
    "    # Fit model to folds\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Get results of grid search\n",
    "    print('Cross validation test score: ', clf.best_score_)\n",
    "    print('Grid search best hyperparameters: ', clf.best_params_)\n",
    "\n",
    "    fitted_model = xgb.XGBRegressor(learning_rate = clf.best_params_['learning_rate'], \n",
    "                                    n_estimators = clf.best_params_['n_estimators'],\n",
    "                                    max_depth = clf.best_params_['max_depth'])\n",
    "    \n",
    "    cvl = cross_val_score(fitted_model, X, y, cv=cv_iter, scoring='neg_mean_squared_error')\n",
    "\n",
    "    print('Cross validation test scores per fold: ', cvl)\n",
    "    print('Mean cross validation test score: ', cvl.mean())\n",
    "    print('Standard deviation: ', cvl.std())\n",
    "\n",
    "    #plot_prediction_per_fold(X, y, fitted_model, cv_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc6bbed-4b66-4aeb-a1e7-fa8e298259b3",
   "metadata": {},
   "source": [
    "### Test for function train_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "83319bb0-ea84-4497-971e-5994a3282722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for function train_xgb_model\n",
    "\n",
    "filepath = 'Data/'\n",
    "\n",
    "df_data_train = pd.read_csv(filepath + 'train_test/data_train_all_job_rdsplit.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2881d26-9ad4-4ba5-9be1-5cec0dfaae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = ['altitude','aspect','slope','slope_factor','altitude_climate']\n",
    "temp_cols = ['t2m_oct','t2m_nov','t2m_des','t2m_jan','t2m_feb','t2m_mar','t2m_apr','t2m_may','t2m_jun','t2m_jul','t2m_aug','t2m_sep']\n",
    "prec_cols = ['tp_oct','tp_nov','tp_des','tp_jan','tp_feb','tp_mar','tp_apr','tp_may','tp_jun','tp_jul','tp_aug','tp_sep']\n",
    "label_cols = ['balance_netto']\n",
    "\n",
    "df_train_X = select_variables(df_data_train, base_cols, temp_cols, prec_cols)\n",
    "df_train_y = select_variables(df_data_train, label_cols)\n",
    "\n",
    "X_train, y_train = df_train_X.values, df_train_y.values\n",
    "#X_test, y_test = df_test_X.values, df_test_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ef6ea150-e843-4d73-a257-bc08cac35172",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_params = {\n",
    "    'max_depth': [2, 4, 6, 8],\n",
    "    'n_estimators': [100, 200, 300], # number of trees (too many = overfitting, too few = underfitting)\n",
    "    'learning_rate': [0.01, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "cv_iter_type = 'kfold' # kfold, logo\n",
    "\n",
    "cv_kwargs = {\n",
    "    'n_folds' : 2,\n",
    "    'shuffle' : True,\n",
    "    'rand_seed' : 5,\n",
    "    'groups' : [1, 1, 2, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "035352c3-cb4e-4c77-9d78-6eec3346d827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "Cross validation test score:  -0.48218868730709985\n",
      "Grid search best hyperparameters:  {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 200}\n",
      "Cross validation test scores per fold:  [-0.5041982  -0.46017917]\n",
      "Mean cross validation test score:  -0.48218868730709985\n",
      "Standard deviation:  0.022009515486137277\n"
     ]
    }
   ],
   "source": [
    "train_xgb_model(X_train, y_train, cv_iter_type, gs_params, **cv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca745e1-bcaa-4c36-9039-894a7d925a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT FINISHED\n",
    "\n",
    "split_specs = {\n",
    "    'split_type' : 'kfold', # kfold, logo, kfold_strat, \n",
    "    'num_folds' : 5,\n",
    "    'shuffle' : False,\n",
    "    'set_rand_state' : 5,\n",
    "}\n",
    "\n",
    "#split_kwargs = {\n",
    "#    'filepath' : 'Data/',\n",
    "#    'filename_save' : \n",
    "#}\n",
    "\n",
    "def train_split_data(df_data, spec_dict, save=False, **kwargs):\n",
    "    \n",
    "    \"\"\" returns train and validation folds for model training\n",
    "\n",
    "    Variables:\n",
    "    df_data : training dataset\n",
    "    spec_dict : dictionary with specification of splitting strategy\n",
    "    save : choice to save datafile\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a9441-5993-4dde-9b5d-4ea82daf5a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
